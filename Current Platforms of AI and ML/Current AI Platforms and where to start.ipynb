{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class [1]: Introduction to Platforms\n",
    "\n",
    "by `Mugume Twinamatsiko Atwine`  \n",
    "- [Github](https://github.com/atwine)\n",
    "- [LinkedIn](https://www.linkedin.com/in/mugume-twinamatsiko-atwine-msc-976ab12b/)\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "- **No Prior Coding Experience**: This tutorial assumes you’re new to programming.  \n",
    "- **A Laptop or Desktop with an Internet Connection**: You’ll need reliable internet access during the lesson.  \n",
    "- **Administrator Privileges**: Make sure you have permission to install software on your computer; otherwise, you may encounter issues with dependency installations.\n",
    "\n",
    "### Learning Outcomes\n",
    "By the end of this tutorial, you will be able to:  \n",
    "1. **Explain** the basics of Big Data and AI platforms.  \n",
    "2. **Install** a working environment for data analysis and AI experiments.  \n",
    "3. **Identify** the most commonly used platforms and why they are favorable.  \n",
    "4. **Get Started** with Jupyter Notebooks for interactive coding and data exploration.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Big Data?\n",
    "\n",
    "**Big Data** refers to extremely large and complex datasets that are difficult or impossible to process using traditional data processing methods. These datasets often exhibit what are known as the **3 Vs**:\n",
    "\n",
    "1. **Volume**: The amount of data is huge (petabytes or more).  \n",
    "2. **Velocity**: The data is generated and must be processed at high speed.  \n",
    "3. **Variety**: The data comes in multiple forms (text, images, sensor data, etc.).\n",
    "\n",
    "### Biological Example: Genomic Sequencing\n",
    "In genomics, high-throughput sequencing technologies can generate billions of short DNA reads in a single experiment. For instance, sequencing a human genome at a coverage of 30x can produce hundreds of gigabytes of raw data, which must be cleaned, assembled, and analyzed to identify genetic variations. This volume, velocity (multiple samples per day), and variety (reads, metadata, related clinical information) make genomics a prime example of **big data** in biology.\n",
    "\n",
    "Why does it matter?  \n",
    "- **Complexity**: Large data sizes require specialized hardware (e.g., HPC clusters) and distributed storage.  \n",
    "- **Advanced Analytics**: Machine learning and AI models can extract insights—such as mutations linked to specific diseases—from the vast troves of genomic data.  \n",
    "- **Collaborative Efforts**: Teams of biologists, data scientists, and computational experts work together to handle these datasets efficiently and ethically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Resources Needed\n",
    "\n",
    "### High Performance Computing (HPC)\n",
    "High Performance Computing refers to the use of supercomputers or computing clusters to run advanced, large-scale computational tasks. These systems have many CPU cores, large amounts of memory, and specialized architectures that enable them to tackle problems that would be infeasible on a standard desktop or laptop computer.\n",
    "\n",
    "**Example Use Case (Biological): Genomic Data Analysis**\n",
    "- Modern genomics research generates massive datasets (e.g., from high-throughput sequencers).\n",
    "- A typical workflow might involve sequencing an organism’s genome and then aligning billions of short DNA reads to a reference genome. This task can be very computationally intensive.\n",
    "- Machine learning: predictive analytics on Electronic Health Records for various objectives like: time to event analytics etc.\n",
    "\n",
    "*(Note: At the ACE, if you have access to HPC resources, you can run these large-scale analyses without overburdening your personal computer.)*\n",
    "\n",
    "### Normally, To Practice, You Need a Powerful Computer\n",
    "\n",
    "- **5+ CPU cores** (e.g., a modern 6-core or 8-core processor).\n",
    "- **4 GB+ of RAM** (more is better—8 GB, 16 GB, or more depending on the projects).\n",
    "- **500 GB+ of HDD space** (or SSD, which is faster; data can quickly balloon in size for ML projects).\n",
    "\n",
    "These specifications are a reasonable starting point for:\n",
    "- Small-scale machine learning tasks.\n",
    "- Basic data analytics and exploration.\n",
    "- Running smaller deep learning models (e.g., on subsets of data).\n",
    "- Some forms of simulation (though they may be slow if the problem grows in complexity).\n",
    "\n",
    "**Why You Might Need More Power**  \n",
    "Once you move to “data-hungry” algorithms such as deep neural networks, your data and model sizes can grow dramatically. Training large neural networks on CPUs alone can be prohibitively slow, hence the need for HPC or specialized hardware.\n",
    "\n",
    "### For Heavy Computing, You Will Need\n",
    "\n",
    "- **GPU (Graphical Processing Unit)**:  \n",
    "  GPUs are very efficient at parallel processing. Originally designed for rendering graphics, they excel at performing many small calculations simultaneously. This makes them ideal for training and running deep learning models.\n",
    "  \n",
    "- **TPU (Tensor Processing Unit)**:  \n",
    "  TPUs are custom-built by certain cloud providers (e.g., Google) specifically for accelerating machine learning (particularly TensorFlow-based) workloads. They can significantly reduce the training time for very large neural networks.\n",
    "\n",
    "**Cost and Access Considerations**  \n",
    "- High-end GPUs or TPUs can be expensive.\n",
    "- HPC clusters often come equipped with these specialized units, allowing users to “rent” or share GPU/TPU time rather than purchasing expensive hardware individually.\n",
    "- Cloud services also provide options to rent GPU/TPU instances on-demand, which can be cost-effective if you only need them for a short time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Platforms:\n",
    "\n",
    "### Free GPU Access Platforms\n",
    "\n",
    "When experimenting with machine learning and deep learning, having access to powerful computing resources like GPUs can be essential. Here are platforms that offer **free GPU usage**:\n",
    "\n",
    "#### [Kaggle](https://www.kaggle.com/)\n",
    "- **What is Kaggle?**  \n",
    "  Kaggle is a leading platform for data science competitions, hosting thousands of public datasets and code notebooks. It allows you to train and test models online without needing powerful hardware on your own machine.\n",
    "  \n",
    "- **Why Use Kaggle?**  \n",
    "  - **Free GPU Access**: Kaggle notebooks (also called “Kernels”) provide free GPU runtime.  \n",
    "  - **Community & Competitions**: Learn from and collaborate with a global community of data scientists.  \n",
    "  - **Datasets**: Access diverse, open-source datasets to practice data analysis and model training.\n",
    "  \n",
    "- **Requirements**  \n",
    "  1. **Sign Up for a Free Account**: You can use your Google account or an email address to register.  \n",
    "  2. **Open a Kaggle Notebook**: Once logged in, create a new notebook (Kernel).  \n",
    "  3. **Enable GPU**: Under Notebook settings, switch the accelerator to ‘GPU.’\n",
    "\n",
    "With these free resources, you can experiment with more computationally intensive tasks without investing in expensive hardware.\n",
    "\n",
    "<img src='kaggle.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb)\n",
    "\n",
    "**What is Google Colab?**  \n",
    "Google Colab (short for “Collaboratory”) is a free, cloud-based Jupyter Notebook environment provided by Google. It allows you to write and execute Python code through your web browser, with no setup required on your local machine.\n",
    "\n",
    "**Key Benefits**  \n",
    "- **Free GPUs and TPUs**: Accelerate machine learning and deep learning tasks with powerful hardware resources, without buying expensive graphics cards or specialized chips.  \n",
    "- **No Installation Needed**: All you need is a Google account and a web browser to start coding.  \n",
    "- **Pre-Installed Libraries**: Many popular Python libraries for data science and machine learning (e.g., NumPy, Pandas, TensorFlow) are already installed.  \n",
    "- **Collaboration**: Share your notebooks with others, comment in real time, and keep your work in the cloud.\n",
    "\n",
    "**How to Use GPU or TPU**  \n",
    "1. Create or open a notebook in Google Colab.  \n",
    "2. Navigate to `Runtime` → `Change runtime type`.  \n",
    "3. Under the “Hardware accelerator” dropdown, select either “GPU” or “TPU.”  \n",
    "4. Click “Save” to confirm, and you’re ready to leverage accelerated computing power.\n",
    "\n",
    "**Getting Started**  \n",
    "1. Go to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).  \n",
    "2. Sign in with your Google account (if you’re not already signed in).  \n",
    "3. Create a new notebook or choose from available demos.  \n",
    "4. Start coding and experimenting right away—no local installation required!\n",
    "\n",
    "---\n",
    "\n",
    "Using Google Colab can significantly speed up your machine learning workflows and is a great resource for beginners looking to experiment with larger models without incurring additional hardware costs.\n",
    "\n",
    "<img src='colab.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with GitHub\n",
    "\n",
    "**What is GitHub?**  \n",
    "GitHub is a popular platform for hosting, sharing, and collaborating on coding projects. It’s widely used by developers and data scientists to store code, track changes, and contribute to open-source communities. \n",
    "\n",
    "**Why Use GitHub?**  \n",
    "- **Collaboration**: Work on projects with others around the world.  \n",
    "- **Version Control**: Keep track of changes in your projects using Git.  \n",
    "- **Open-Source Learning**: Explore countless public repositories, fork and clone them to learn and practice.\n",
    "\n",
    "### Steps to Get the Teaching Materials\n",
    "\n",
    "1. **Create a GitHub Account**  \n",
    "   - Sign up for free at [GitHub](https://github.com/).  \n",
    "   - Having an account allows you to access, fork, and star repositories, as well as contribute to open-source projects.\n",
    "\n",
    "2. **Install Git**  \n",
    "   - Download Git from [git-scm.com](https://git-scm.com/).  \n",
    "   - Follow the installation instructions for your operating system.  \n",
    "   - After installation, you’ll have the Git command line available to clone repositories and manage version control.\n",
    "\n",
    "3. **Clone the Repository**  \n",
    "   - Cloning means making a local copy of the project on your computer.  \n",
    "   - Replace the URL below with any other repository you want to clone.\n",
    "\n",
    "   **In Jupyter Notebook**  \n",
    "   ```bash\n",
    "   !git clone https://github.com/aceuganda/BigDataClass-ACE-2025.git\n",
    "   ```\n",
    "\n",
    "   **On the Command Line**  \n",
    "   ```bash\n",
    "   git clone https://github.com/aceuganda/BigDataClass-ACE-2025.git\n",
    "   ```\n",
    "\n",
    "Once you have cloned the repository, you can start exploring the materials locally, make changes, and experiment with the code. Be sure to commit and push your changes back to GitHub if you want to keep them synchronized or share them with others.\n",
    "\n",
    "---\n",
    "\n",
    "<img src='github.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started (Locally)\n",
    "\n",
    "Setting up a local environment for data science or machine learning can be straightforward once you know the basic tools you need. Below are some essentials to help you get started.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Install Python\n",
    "\n",
    "[**Python**](https://www.python.org/) is one of the most widely used programming languages in machine learning and artificial intelligence. Its syntax is relatively easy to learn, and it’s open-source, meaning it’s free and has a large community contributing helpful libraries and tools.\n",
    "\n",
    "- **Check Your Version**: Most modern computers have Python installed by default. You can check your version by running `python --version` in your terminal or command prompt.\n",
    "- **Upgrade if Needed**: If you need a newer version of Python, you can download the installer for your operating system from the official [Python website](https://www.python.org/).\n",
    "- **To check if you have python**: To check if you have python, please open command line on your computer/terminal and type 'python' if the response is: the command is not recognized then there is no python: otherwise you will see the command prompt change and ready for further instructions.\n",
    "\n",
    "*<img src='python.png'/>*\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Choose an Environment\n",
    "\n",
    "To start coding, you need an environment where you can write and run your code. There are multiple options available. Below are two popular ones.\n",
    "\n",
    "#### **Option A: Anaconda**\n",
    "\n",
    "[Anaconda](https://www.anaconda.com/) is a distribution that comes with Python, R, and many of the libraries you need for data science already pre-installed. It simplifies package management and deployment, especially for beginners.\n",
    "\n",
    "- **Why Anaconda?**  \n",
    "  - It includes **conda**, a package manager that makes installing libraries (e.g., NumPy, Pandas, TensorFlow) very convenient.  \n",
    "  - Comes with **Jupyter Notebook**, **RStudio**, and other tools in one package.  \n",
    "- **Installation**: Download the installer for your operating system from the [Anaconda website](https://www.anaconda.com/). Follow the on-screen instructions.\n",
    "\n",
    "*<img src='anaconda.png'/>*\n",
    "\n",
    "##### **Anaconda Navigator**\n",
    "\n",
    "Once you install Anaconda, you can use the **Anaconda Navigator**, a graphical interface that lets you launch different applications, including Jupyter Notebook and RStudio, without needing to use the command line.\n",
    "\n",
    "*<img src='anaconda navigator.png'/>*\n",
    "\n",
    "#### **Option B: R Studio**\n",
    "\n",
    "If you’re interested in using **R** for data science, [RStudio](https://posit.co/products/open-source/rstudio/) is a popular integrated development environment (IDE). You can also launch RStudio via the Anaconda Navigator if you install the R-related packages.\n",
    "\n",
    "*<img src='rstudio.png'/>*\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Jupyter Notebooks\n",
    "\n",
    "[**Jupyter Notebooks**](https://jupyter.org/) are interactive computational notebooks that let you combine code, text, images, and even widgets in a single document. They’re especially popular in data science because you can see outputs (like graphs or data tables) immediately below the code that generated them.\n",
    "\n",
    "- **Why Jupyter?**  \n",
    "  - **Beginner-Friendly**: Easy to set up and start coding for AI/ML tasks.  \n",
    "  - **Interactive**: Lets you run code cells step by step and see results instantly.  \n",
    "  - **Rich Media**: You can embed images, plots, videos, and interactive widgets directly in your notebook.\n",
    "\n",
    "**Quick Setup**  \n",
    "- If you installed Anaconda, you already have Jupyter Notebook. Just launch it from Anaconda Navigator or open your terminal and type:\n",
    "  ```bash\n",
    "  jupyter notebook\n",
    "  ```\n",
    "- A web browser will open showing your Jupyter interface. You can then create or open `.ipynb` files (Jupyter Notebook files).\n",
    "\n",
    "**Great Resource**  \n",
    "- [Starters Guide to Jupyter Notebook](https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/) by Analytics Vidhya.\n",
    "\n",
    "*<img src='Jupyternotebooks.png'/>*\n",
    "\n",
    "---\n",
    "\n",
    "### Extra Fun: Jupyter Notebook Widgets\n",
    "\n",
    "You can build interactive widgets within Jupyter Notebooks to create sliders, buttons, and other UI elements that make your data exploration more engaging.\n",
    "\n",
    "*<img src='Jupyterwidget.gif'/>*\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "1. **Install Python** if you don’t have it, or update to the latest version.  \n",
    "2. **Use Anaconda** to manage your Python and R environments seamlessly.  \n",
    "3. **Launch Jupyter Notebooks** from Anaconda or your terminal to start experimenting with machine learning and data science code in an interactive environment.  \n",
    "4. **Optional**: If you prefer R for data science, explore **RStudio**, which you can also install via Anaconda.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation in Software Libraries\n",
    "\n",
    "**What Is Documentation?**  \n",
    "Documentation refers to the written guides, examples, reference materials, and how-to instructions provided by the creators or maintainers of a software library or tool. It usually covers everything from installation steps to advanced usage, detailing the library’s classes, methods, functions, and sometimes common pitfalls or best practices.\n",
    "\n",
    "**Why It Matters**  \n",
    "1. **Learning the Basics**: Good documentation offers tutorials and quick-start guides that help beginners understand how to install and use the library right away.  \n",
    "2. **Detailed Reference**: More advanced sections (e.g., API references) describe functions, classes, and parameters in depth, making it easy to find exactly what you need without guesswork.  \n",
    "3. **Troubleshooting**: Documentation often includes FAQs or troubleshooting tips that save you time when you encounter errors or unexpected behavior.  \n",
    "4. **Staying Up-to-Date**: Libraries evolve over time with new releases. The documentation is usually updated to reflect new features or changes, helping you stay current.  \n",
    "5. **Community & Best Practices**: Many documentation sites link to official forums, GitHub issues, or best-practice guides—valuable if you’re building larger applications or want to contribute to the codebase.\n",
    "\n",
    "**Practical Tips for Using Documentation**\n",
    "- **Start with the “Getting Started” Guide**: If the docs have a quick-start section, read it first to get an overview.  \n",
    "- **Use the Search Feature**: Online docs often have a built-in search. Use it to quickly locate methods or functions relevant to your project.  \n",
    "- **Check Version Compatibility**: Make sure you’re viewing the documentation that matches your installed library version.  \n",
    "- **Look for Code Examples**: Many docs include example snippets. Copy them, run them, and modify them to learn by doing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Virtual Environments\n",
    "\n",
    "### What Is a Virtual Environment?\n",
    "A **virtual environment** is an isolated space on your computer where you can install specific versions of Python and libraries without affecting the rest of your system (or other projects). Think of it as a “sandbox” that keeps your project’s dependencies separate from everything else.\n",
    "\n",
    "### Why Do We Need Virtual Environments?\n",
    "- **Dependency Management**: Different projects may require different library versions. If you install everything system-wide, there can be conflicts—one project might need `numpy` version 1.18 while another requires 1.21.  \n",
    "- **Cleaner Upgrades**: You can upgrade or downgrade libraries in one environment without breaking other projects.  \n",
    "- **Project Portability**: It’s easier to share your work. You can list the environment’s packages and versions in a file (e.g., `environment.yml` for Conda), and others can recreate the same environment.\n",
    "\n",
    "### Creating a Virtual Environment with Anaconda\n",
    "\n",
    "1. **Install Anaconda** (if you haven’t already).  \n",
    "2. **Open a Terminal or Anaconda Prompt**.\n",
    "\n",
    "```bash\n",
    "# Step 1: Create a new environment called \"myenv\" \n",
    "# and specify the Python version you want.\n",
    "conda create --name myenv python=3.9\n",
    "\n",
    "# Step 2: Activate the environment.\n",
    "conda activate myenv\n",
    "\n",
    "# Step 3: Install additional libraries if needed.\n",
    "# Example: Installing Jupyter\n",
    "pip install jupyter\n",
    "\n",
    "# Step 4: Launch Jupyter (optional)\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "3. **Deactivate When Done**  \n",
    "   ```bash\n",
    "   conda deactivate\n",
    "   ```\n",
    "   This returns you to your base environment.\n",
    "\n",
    "### Tips & Best Practices\n",
    "- **Name Your Environments Wisely**: Use descriptive names like `ml-env`, `projectX-env`, or `tensorflow-env`.  \n",
    "- **Keep an `environment.yml` file**: You can generate one with `conda env export > environment.yml`. This file lists all packages, allowing others (or future you) to recreate the environment with `conda env create -f environment.yml`.  \n",
    "- **Avoid “Base” Environment**: Install your tools and libraries in separate environments instead of cluttering your base environment.\n",
    "- **Note**: This step is normally done after installing anaconda or python on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
